{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "667ad68d",
   "metadata": {},
   "source": [
    "# Evaluación del modelo de lenguaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f1dc6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import json\n",
    "import re\n",
    "import html\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import gc\n",
    "from pathlib import Path\n",
    "from lxml import etree\n",
    "from collections import Counter\n",
    "from typing import Dict, List, Tuple\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fa1c17",
   "metadata": {},
   "source": [
    "Se definen los PATHS a los datos. En caso de necesitarlo aquí es donde se modifican para poder utilizar los datos locales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a82253f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_BAC = \"data/BAC/blogs\"  # Cambia esta ruta por la de tu carpeta con archivos XML\n",
    "OUTPUT_BAC_JSONL = \"data/processed/BAC.jsonl\"\n",
    "PATH_TO_20NG = \"data/20news-18828/\"  # Cambia esta ruta por la de tu carpeta con archivos de 20 Newsgroups\n",
    "OUTPUT_20NG_JSONL = \"data/processed/20news.jsonl\"\n",
    "\n",
    "OUTPUT_20NG_TOKENIZED_JSONL = \"data/processed/20news_tokenized.jsonl\"\n",
    "OUTPUT_BAC_TOKENIZED_JSONL = \"data/processed/BAC_tokenized.jsonl\"\n",
    "\n",
    "\n",
    "GROUP_ID = \"0100\"\n",
    "OUTPUT_20NG_SPLITS_JSONL = f\"splits/20N_{GROUP_ID}_training.jsonl\"\n",
    "OUTPUT_BAC_SPLITS_JSONL = f\"splits/BAC_{GROUP_ID}_training.jsonl\"\n",
    "\n",
    "\n",
    "TEST_20NG_SPLITS_JSONL = f\"splits/20N_{GROUP_ID}_testing.jsonl\"\n",
    "TEST_BAC_SPLITS_JSONL = f\"splits/BAC_{GROUP_ID}_testing.jsonl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd183883",
   "metadata": {},
   "source": [
    "## Carga de los archivos Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "158c75a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ngrams/unigrams_20n.pkl', 'rb') as f:\n",
    "    unigrams_20n = pickle.load(f)\n",
    "\n",
    "with open('ngrams/context_counts_unigrams_20n.pkl', 'rb') as f:\n",
    "    context_counts_uni_20n = pickle.load(f)\n",
    "\n",
    "with open('ngrams/bigrams_20n.pkl', 'rb') as f:\n",
    "    bigrams_20n = pickle.load(f)\n",
    "\n",
    "with open('ngrams/context_counts_bigrams_20n.pkl', 'rb') as f:\n",
    "    context_counts_bi_20n = pickle.load(f)\n",
    "\n",
    "with open('ngrams/trigrams_20n.pkl', 'rb') as f:\n",
    "    trigrams_20n = pickle.load(f)\n",
    "\n",
    "with open('ngrams/context_counts_trigrams_20n.pkl', 'rb') as f:\n",
    "    context_counts_tri_20n = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcc06a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INFORMACIÓN GENERAL ===\n",
      "Tipo unigrams: <class 'dict'>\n",
      "Tipo bigrams: <class 'dict'>\n",
      "Tipo trigrams: <class 'dict'>\n",
      "\n",
      "Cantidad de unigrams: 72174\n",
      "Cantidad de bigrams: 941694\n",
      "Cantidad de trigrams: 2342730\n"
     ]
    }
   ],
   "source": [
    "print(\"=== INFORMACIÓN GENERAL ===\")\n",
    "print(f\"Tipo unigrams: {type(unigrams_20n)}\")\n",
    "print(f\"Tipo bigrams: {type(bigrams_20n)}\")\n",
    "print(f\"Tipo trigrams: {type(trigrams_20n)}\")\n",
    "\n",
    "print(f\"\\nCantidad de unigrams: {len(unigrams_20n)}\")\n",
    "print(f\"Cantidad de bigrams: {len(bigrams_20n)}\")\n",
    "print(f\"Cantidad de trigrams: {len(trigrams_20n)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cae04546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PRIMEROS 10 UNIGRAMS ===\n",
      "('<s>',): 0.03759524512819843\n",
      "('is',): 0.009200650824709796\n",
      "('it',): 0.007095915046812705\n",
      "('worth',): 8.600416801983155e-05\n",
      "('to',): 0.015476670349451091\n",
      "('run',): 0.00026421394311974816\n",
      "('atm',): 7.343809413458102e-06\n",
      "('at',): 0.0022356187812213896\n",
      "('all',): 0.001921956521384357\n",
      "('?',): 0.006548393256098218\n",
      "\n",
      "=== PRIMEROS 10 BIGRAMS ===\n",
      "('<s>', 'is'): 0.0045646554858498984\n",
      "('is', 'it'): 0.007413400129131629\n",
      "('it', 'worth'): 0.00019022256039566293\n",
      "('worth', 'it'): 0.0006327372764786795\n",
      "('it', 'to'): 0.007997994016635828\n",
      "('to', 'run'): 0.002305278789040046\n",
      "('run', 'atm'): 9.486123156981787e-05\n",
      "('atm', 'at'): 8.308178016560969e-05\n",
      "('at', 'all'): 0.009886808272778089\n",
      "('all', '?'): 0.0008219178082191781\n",
      "\n",
      "=== PRIMEROS 10 TRIGRAMS ===\n",
      "('<s>', 'is', 'it'): 0.0034260543274329063\n",
      "('is', 'it', 'worth'): 0.00020512539999453\n",
      "('it', 'worth', 'it'): 0.0001246623727404945\n",
      "('worth', 'it', 'to'): 0.0001938548027527382\n",
      "('it', 'to', 'run'): 0.00019152370789898493\n",
      "('to', 'run', 'atm'): 8.269246671628214e-05\n",
      "('run', 'atm', 'at'): 8.312551953449709e-05\n",
      "('atm', 'at', 'all'): 8.31266711924521e-05\n",
      "('at', 'all', '?'): 0.0006436416422448029\n",
      "('all', '?', '</s>'): 0.0008166994269261648\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== PRIMEROS 10 UNIGRAMS ===\")\n",
    "if isinstance(unigrams_20n, dict):\n",
    "    # Si es diccionario, mostrar primeros items\n",
    "    for i, (key, value) in enumerate(list(unigrams_20n.items())[:10]):\n",
    "        print(f\"{key}: {value}\")\n",
    "else:\n",
    "    # Si es lista, mostrar primeros elementos\n",
    "    print(unigrams_20n[:10])\n",
    "\n",
    "\n",
    "print(\"\\n=== PRIMEROS 10 BIGRAMS ===\")\n",
    "if isinstance(bigrams_20n, dict):\n",
    "    for i, (key, value) in enumerate(list(bigrams_20n.items())[:10]):\n",
    "        print(f\"{key}: {value}\")\n",
    "else:\n",
    "    print(bigrams_20n[:10])\n",
    "\n",
    "print(\"\\n=== PRIMEROS 10 TRIGRAMS ===\")\n",
    "if isinstance(trigrams_20n, dict):\n",
    "    for i, (key, value) in enumerate(list(trigrams_20n.items())[:10]):\n",
    "        print(f\"{key}: {value}\")\n",
    "else:\n",
    "    print(trigrams_20n[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1447b144",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ngrams/unigrams_bac.pkl', 'rb') as f:\n",
    "    unigrams_bac = pickle.load(f)\n",
    "\n",
    "with open('ngrams/context_counts_unigrams_bac.pkl', 'rb') as f:\n",
    "    context_counts_uni = pickle.load(f)\n",
    "\n",
    "with open('ngrams/bigrams_bac.pkl', 'rb') as f:\n",
    "    bigrams_bac = pickle.load(f)\n",
    "\n",
    "with open('ngrams/context_counts_bigrams_bac.pkl', 'rb') as f:\n",
    "    context_counts_bi = pickle.load(f)\n",
    "\n",
    "with open('ngrams/trigrams_bac.pkl', 'rb') as f:\n",
    "    trigrams_bac = pickle.load(f)\n",
    "\n",
    "with open('ngrams/context_counts_trigrams_bac.pkl', 'rb') as f:\n",
    "    context_counts_tri = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adb0cf39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INFORMACIÓN GENERAL ===\n",
      "Tipo unigrams: <class 'dict'>\n",
      "Tipo bigrams: <class 'dict'>\n",
      "Tipo trigrams: <class 'dict'>\n",
      "\n",
      "Cantidad de unigrams: 386329\n",
      "Cantidad de bigrams: 9861802\n",
      "Cantidad de trigrams: 38191007\n"
     ]
    }
   ],
   "source": [
    "print(\"=== INFORMACIÓN GENERAL ===\")\n",
    "print(f\"Tipo unigrams: {type(unigrams_bac)}\")\n",
    "print(f\"Tipo bigrams: {type(bigrams_bac)}\")\n",
    "print(f\"Tipo trigrams: {type(trigrams_bac)}\")\n",
    "\n",
    "print(f\"\\nCantidad de unigrams: {len(unigrams_bac)}\")\n",
    "print(f\"Cantidad de bigrams: {len(bigrams_bac)}\")\n",
    "print(f\"Cantidad de trigrams: {len(trigrams_bac)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8054075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PRIMEROS 10 UNIGRAMS ===\n",
      "('<s>',): 0.049583917069526466\n",
      "('just',): 0.003068443153250799\n",
      "('a',): 0.015964224080597066\n",
      "('few',): 0.0005275043847319924\n",
      "('weeks',): 0.00019377825625771782\n",
      "('ago',): 0.00022502227066114588\n",
      "(',',): 0.03351788743120267\n",
      "('an',): 0.0017274539492573284\n",
      "('army',): 3.6994915785941965e-05\n",
      "('vehicle',): 1.5243017932854284e-05\n",
      "\n",
      "=== PRIMEROS 10 BIGRAMS ===\n",
      "('<s>', 'just'): 0.003949886858158352\n",
      "('just', 'a'): 0.026262081898931946\n",
      "('a', 'few'): 0.020871799078313522\n",
      "('few', 'weeks'): 0.010006815452686694\n",
      "('weeks', 'ago'): 0.007911751498090267\n",
      "('ago', ','): 0.01893060926181133\n",
      "(',', 'an'): 0.0013558523786191357\n",
      "('an', 'army'): 0.0006349036301363389\n",
      "('army', 'vehicle'): 1.0213252716725222e-05\n",
      "('vehicle', 'was'): 0.0001492844641202512\n",
      "\n",
      "=== PRIMEROS 10 TRIGRAMS ===\n",
      "('<s>', 'just', 'a'): 0.005538221903859929\n",
      "('just', 'a', 'few'): 0.004268959128759845\n",
      "('a', 'few', 'weeks'): 0.006228705401451933\n",
      "('few', 'weeks', 'ago'): 0.0026908605382232648\n",
      "('weeks', 'ago', ','): 0.002197097059842661\n",
      "('ago', ',', 'an'): 4.058297442765324e-05\n",
      "(',', 'an', 'army'): 5.8466599048773855e-05\n",
      "('an', 'army', 'vehicle'): 5.171553353623061e-06\n",
      "('army', 'vehicle', 'was'): 5.176894484536616e-06\n",
      "('vehicle', 'was', 'blown'): 5.176170979279787e-06\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== PRIMEROS 10 UNIGRAMS ===\")\n",
    "if isinstance(unigrams_bac, dict):\n",
    "    # Si es diccionario, mostrar primeros items\n",
    "    for i, (key, value) in enumerate(list(unigrams_bac.items())[:10]):\n",
    "        print(f\"{key}: {value}\")\n",
    "else:\n",
    "    # Si es lista, mostrar primeros elementos\n",
    "    print(unigrams_bac[:10])\n",
    "\n",
    "print(\"\\n=== PRIMEROS 10 BIGRAMS ===\")\n",
    "if isinstance(bigrams_bac, dict):\n",
    "    for i, (key, value) in enumerate(list(bigrams_bac.items())[:10]):\n",
    "        print(f\"{key}: {value}\")\n",
    "else:\n",
    "    print(bigrams_bac[:10])\n",
    "\n",
    "print(\"\\n=== PRIMEROS 10 TRIGRAMS ===\")\n",
    "if isinstance(trigrams_bac, dict):\n",
    "    for i, (key, value) in enumerate(list(trigrams_bac.items())[:10]):\n",
    "        print(f\"{key}: {value}\")\n",
    "else:\n",
    "    print(trigrams_bac[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937f9952",
   "metadata": {},
   "source": [
    "## Cálculo de la perplejidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bc10248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_sentences(file_path: str) -> List[List[str]]:\n",
    "    \"\"\"\n",
    "    Carga y tokeniza las oraciones de un archivo JSONL de prueba.\n",
    "    \"\"\"\n",
    "    test_sentences = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            sentence = data['sentence']\n",
    "\n",
    "            test_sentences.append(sentence)\n",
    "    return test_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e071bf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_sentences_20n = load_test_sentences(TEST_20NG_SPLITS_JSONL)\n",
    "test_sentences_bac = load_test_sentences(TEST_BAC_SPLITS_JSONL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "800bcdd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cantidad de oraciones de prueba en 20 Newsgroups: 57592\n",
      "Cantidad de oraciones de prueba en BAC: 1782586\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nCantidad de oraciones de prueba en 20 Newsgroups: {len(test_sentences_20n)}\")\n",
    "print(f\"Cantidad de oraciones de prueba en BAC: {len(test_sentences_bac)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2620ea20",
   "metadata": {},
   "source": [
    "Se genera una clase que permita generar un modelo de lenguaje a partir de las probabilidades de n-gramas ya calculadas. De esta manera se pueden manejar métodos comunes como el cálculo de la perplejidad y la generación de oraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "27e88ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NgramModel:\n",
    "    \"\"\"\n",
    "    Modelo de n-gramas que maneja predicción, generación y evaluación.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, ngram_probs: Dict[Tuple[str, ...], float], \n",
    "                 context_counts: Dict[Tuple[str, ...], int],\n",
    "                 n: int, \n",
    "                 laplace: float = 1.0):\n",
    "        \"\"\"\n",
    "        Inicializa el modelo con las probabilidades de n-gramas y context_counts reales.\n",
    "        \n",
    "        Args:\n",
    "            ngram_probs: Diccionario con probabilidades de n-gramas entrenados\n",
    "            context_counts: Diccionario con conteos de contextos del entrenamiento\n",
    "            n: Tamaño del n-grama (1, 2, 3, etc.)\n",
    "            laplace: Parámetro de suavizado de Laplace\n",
    "        \"\"\"\n",
    "        self.ngram_probs = ngram_probs\n",
    "        self.context_counts = context_counts if context_counts else {}\n",
    "        self.n = n\n",
    "        self.laplace = laplace\n",
    "        \n",
    "        # Calcular información derivada\n",
    "        self._calculate_vocab_info()\n",
    "    \n",
    "    def _calculate_vocab_info(self):\n",
    "        \"\"\"Calcula solo vocabulary y vocab_size desde los n-gramas.\"\"\"\n",
    "        \n",
    "        # Extraer vocabulario completo\n",
    "        self.vocabulary = set()\n",
    "        for ngram in self.ngram_probs.keys():\n",
    "            self.vocabulary.update(ngram)\n",
    "        self.vocab_size = len(self.vocabulary)\n",
    "        \n",
    "        # Para unigramas, calcular total si es necesario\n",
    "        if self.n == 1:\n",
    "            self.total_unigrams = len(self.ngram_probs)\n",
    "    \n",
    "    def predict_next_word(self, context: List[str]) -> Tuple[str, float]:\n",
    "        \"\"\"\n",
    "        Predice la siguiente palabra más probable dado un contexto.\n",
    "        \n",
    "        Args:\n",
    "            context: Lista de palabras que forman el contexto\n",
    "        \n",
    "        Returns:\n",
    "            Tuple[str, float]: (palabra_predicha, probabilidad)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Para unigramas, muestreo aleatorio ponderado\n",
    "        if self.n == 1:\n",
    "            candidates = {ngram[0]: prob for ngram, prob in self.ngram_probs.items()}\n",
    "            \n",
    "            if candidates:\n",
    "                # Muestreo ponderado por probabilidad\n",
    "                words = list(candidates.keys())\n",
    "                probs = list(candidates.values())\n",
    "                chosen_word = random.choices(words, weights=probs, k=1)[0]\n",
    "                chosen_prob = candidates[chosen_word]\n",
    "                return chosen_word, chosen_prob\n",
    "        \n",
    "        # Para n-gramas superiores, tomar las últimas n-1 palabras\n",
    "        else:\n",
    "            if len(context) >= self.n - 1:\n",
    "                relevant_context = context[-(self.n-1):]\n",
    "            else:\n",
    "                relevant_context = context\n",
    "            \n",
    "            context_tuple = tuple(relevant_context)\n",
    "            \n",
    "            # Buscar todos los n-gramas que empiecen con este contexto\n",
    "            candidates = {}\n",
    "            for ngram, prob in self.ngram_probs.items():\n",
    "                if ngram[:-1] == context_tuple:\n",
    "                    next_word = ngram[-1]\n",
    "                    candidates[next_word] = prob\n",
    "            \n",
    "            if candidates:\n",
    "                best_word = max(candidates, key=candidates.get)\n",
    "                best_prob = candidates[best_word]\n",
    "                return best_word, best_prob\n",
    "\n",
    "        uniform_prob = 1.0 / self.vocab_size\n",
    "        return random.choice(list(self.vocabulary)), uniform_prob\n",
    "    \n",
    "    def get_ngram_probability(self, ngram: Tuple[str, ...]) -> float:\n",
    "        \"\"\"\n",
    "        Calcula la probabilidad de un n-grama específico usando suavizado de Laplace.\n",
    "        \n",
    "        Args:\n",
    "            ngram: N-grama a evaluar\n",
    "            \n",
    "        Returns:\n",
    "            float: Probabilidad del n-grama\n",
    "        \"\"\"\n",
    "        \n",
    "        # Si el n-grama fue visto durante entrenamiento\n",
    "        if ngram in self.ngram_probs:\n",
    "            return self.ngram_probs[ngram]\n",
    "        \n",
    "        # Si no fue visto, aplicar suavizado de Laplace correcto\n",
    "        if self.n == 1:\n",
    "            # Para unigramas no vistos - usar aproximación o 1/vocab_size para OOV\n",
    "            return 1.0 / self.vocab_size\n",
    "        else:\n",
    "            # Para n-gramas superiores\n",
    "            context = ngram[:-1]\n",
    "            \n",
    "            if context in self.context_counts:\n",
    "                # Contexto conocido: usar count real\n",
    "                context_count = self.context_counts[context]\n",
    "                return self.laplace / (context_count + self.laplace * self.vocab_size)\n",
    "            else:\n",
    "                # Contexto no visto: probabilidad uniforme\n",
    "                return 1.0 / self.vocab_size\n",
    "    \n",
    "    def calculate_perplexity(self, test_sentences: List[List[str]]) -> float:\n",
    "        \"\"\"\n",
    "        Calcula la perplejidad del modelo sobre un conjunto de prueba.\n",
    "        \n",
    "        Args:\n",
    "            test_sentences: Lista de oraciones tokenizadas para evaluar\n",
    "        \n",
    "        Returns:\n",
    "            float: Valor de perplejidad\n",
    "        \"\"\"\n",
    "        \n",
    "        total_log_prob = 0.0\n",
    "        total_ngrams = 0\n",
    "        unseen_count = 0\n",
    "        \n",
    "        for sentence in test_sentences:\n",
    "            # Generar n-gramas de la oración\n",
    "            for i in range(len(sentence) - self.n + 1):\n",
    "                ngram = tuple(sentence[i:i + self.n])\n",
    "                \n",
    "                if ngram in self.ngram_probs:\n",
    "                    # N-grama visto: usar su probabilidad\n",
    "                    prob = self.ngram_probs[ngram]\n",
    "                else:\n",
    "                    # N-grama no visto: usar suavizado correcto\n",
    "                    unseen_count += 1\n",
    "                    prob = self.get_ngram_probability(ngram)\n",
    "                \n",
    "                total_log_prob += math.log(prob)\n",
    "                total_ngrams += 1\n",
    "        \n",
    "        if total_ngrams == 0:\n",
    "            return float('inf')\n",
    "        \n",
    "        # Calcular perplejidad\n",
    "        avg_log_prob = total_log_prob / total_ngrams\n",
    "        perplexity = math.exp(-avg_log_prob)\n",
    "\n",
    "        print(f\"Estadísticas para {self.n}-gramas:\")\n",
    "        print(f\"  Total n-gramas evaluados: {total_ngrams}\")\n",
    "        print(f\"  N-gramas no vistos: {unseen_count}\")\n",
    "        print(f\"  Perplejidad: {perplexity:.4f}\")\n",
    "\n",
    "        return perplexity\n",
    "\n",
    "    def get_model_info(self) -> Dict:\n",
    "        \"\"\"Retorna información del modelo.\"\"\"\n",
    "        return {\n",
    "            'n': self.n,\n",
    "            'laplace': self.laplace,\n",
    "            'vocab_size': self.vocab_size,\n",
    "            'num_ngrams': len(self.ngram_probs),\n",
    "            'num_contexts': len(self.context_counts)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "923ade32",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_20n_uni = NgramModel(unigrams_20n, context_counts_uni_20n, n=1)\n",
    "model_20n_bi = NgramModel(bigrams_20n, context_counts_bi_20n, n=2)\n",
    "model_20n_tri = NgramModel(trigrams_20n, context_counts_tri_20n, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f4fd3180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n': 3,\n",
       " 'laplace': 1.0,\n",
       " 'vocab_size': 72174,\n",
       " 'num_ngrams': 2342730,\n",
       " 'num_contexts': 939236}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_20n_tri.get_model_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "398882be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bac_uni = NgramModel(unigrams_bac, context_counts_uni, n=1)\n",
    "model_bac_bi = NgramModel(bigrams_bac, context_counts_bi, n=2)\n",
    "model_bac_tri = NgramModel(trigrams_bac, context_counts_tri, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42c7e64f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n': 3,\n",
       " 'laplace': 1.0,\n",
       " 'vocab_size': 72174,\n",
       " 'num_ngrams': 2342730,\n",
       " 'num_contexts': 939236}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_20n_tri.get_model_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bce40f0",
   "metadata": {},
   "source": [
    "## Evaluación de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f09bbc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_all_ngrams(test_sentences: List[List[str]], \n",
    "                       unigram_model: NgramModel, \n",
    "                       bigram_model: NgramModel, \n",
    "                       trigram_model: NgramModel) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Evalúa perplejidad para todos los modelos de n-gramas usando objetos NgramModel.\n",
    "    \n",
    "    Args:\n",
    "        test_sentences: Oraciones de prueba\n",
    "        unigram_model: Modelo de unigramas (NgramModel)\n",
    "        bigram_model: Modelo de bigramas (NgramModel)\n",
    "        trigram_model: Modelo de trigramas (NgramModel)\n",
    "    \n",
    "    Returns:\n",
    "        Dict con perplejidades de cada modelo\n",
    "    \"\"\"\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"EVALUACIÓN DE PERPLEJIDAD\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Evaluar unigramas\n",
    "    print(\"\\n   UNIGRAMAS:\")\n",
    "    results['unigrams'] = unigram_model.calculate_perplexity(test_sentences)\n",
    "    \n",
    "    # Evaluar bigramas\n",
    "    print(\"\\n   BIGRAMAS:\")\n",
    "    results['bigrams'] = bigram_model.calculate_perplexity(test_sentences)\n",
    "    \n",
    "    # Evaluar trigramas\n",
    "    print(\"\\n   TRIGRAMAS:\")\n",
    "    results['trigrams'] = trigram_model.calculate_perplexity(test_sentences)\n",
    "    \n",
    "    # Resumen comparativo\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"RESUMEN COMPARATIVO\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for model, perplexity in results.items():\n",
    "        print(f\"{model.upper():<12}: {perplexity:>8.2f}\")\n",
    "    \n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1b56e485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "EVALUACIÓN DE PERPLEJIDAD\n",
      "==================================================\n",
      "\n",
      "   UNIGRAMAS:\n",
      "Estadísticas para 1-gramas:\n",
      "  Total n-gramas evaluados: 1503195\n",
      "  N-gramas no vistos: 3095\n",
      "  Perplejidad: 637.8866\n",
      "\n",
      "   BIGRAMAS:\n",
      "Estadísticas para 2-gramas:\n",
      "  Total n-gramas evaluados: 1445603\n",
      "  N-gramas no vistos: 136116\n",
      "  Perplejidad: 981.5244\n",
      "\n",
      "   TRIGRAMAS:\n",
      "Estadísticas para 3-gramas:\n",
      "  Total n-gramas evaluados: 1388011\n",
      "  N-gramas no vistos: 422560\n",
      "  Perplejidad: 7127.5982\n",
      "\n",
      "==================================================\n",
      "RESUMEN COMPARATIVO\n",
      "==================================================\n",
      "UNIGRAMS    :   637.89\n",
      "BIGRAMS     :   981.52\n",
      "TRIGRAMS    :  7127.60\n"
     ]
    }
   ],
   "source": [
    "perplexity_results = evaluate_all_ngrams(\n",
    "    test_sentences_20n,\n",
    "    model_20n_uni,\n",
    "    model_20n_bi,\n",
    "    model_20n_tri\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "efc7ce17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "EVALUACIÓN DE PERPLEJIDAD\n",
      "==================================================\n",
      "\n",
      "   UNIGRAMAS:\n",
      "Estadísticas para 1-gramas:\n",
      "  Total n-gramas evaluados: 35828187\n",
      "  N-gramas no vistos: 16252\n",
      "  Perplejidad: 656.3425\n",
      "\n",
      "   BIGRAMAS:\n",
      "Estadísticas para 2-gramas:\n",
      "  Total n-gramas evaluados: 34045601\n",
      "  N-gramas no vistos: 1528478\n",
      "  Perplejidad: 734.1268\n",
      "\n",
      "   TRIGRAMAS:\n",
      "Estadísticas para 3-gramas:\n",
      "  Total n-gramas evaluados: 32263015\n",
      "  N-gramas no vistos: 7196407\n",
      "  Perplejidad: 11842.1412\n",
      "\n",
      "==================================================\n",
      "RESUMEN COMPARATIVO\n",
      "==================================================\n",
      "UNIGRAMS    :   656.34\n",
      "BIGRAMS     :   734.13\n",
      "TRIGRAMS    : 11842.14\n"
     ]
    }
   ],
   "source": [
    "perplexity_results = evaluate_all_ngrams(\n",
    "        test_sentences_bac,\n",
    "        model_bac_uni,\n",
    "        model_bac_bi,\n",
    "        model_bac_tri\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06235223",
   "metadata": {},
   "source": [
    "## Predicción de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4da01abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(model: NgramModel,\n",
    "                     initial_context: List[str],\n",
    "                     stop_tokens: List[str] = ['</s>'],\n",
    "                     max_length: int = 20,\n",
    "                     include_context: bool = True) -> List[str]:\n",
    "    \"\"\"\n",
    "    Genera una oración completa usando un modelo de n-gramas entrenado.\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo de n-gramas entrenado (NgramModel)\n",
    "        initial_context: Contexto inicial para empezar la generación\n",
    "        stop_tokens: Lista de tokens que indican fin de oración\n",
    "        max_length: Número máximo de palabras a generar (sin contar contexto inicial)\n",
    "        include_context: Si True, incluye el contexto inicial en la oración final\n",
    "    \n",
    "    Returns:\n",
    "        List[str]: Oración generada como lista de palabras\n",
    "    \"\"\"\n",
    "    \n",
    "    generated_words = []\n",
    "    current_context = initial_context.copy()\n",
    "    \n",
    "    for i in range(max_length):\n",
    "        next_word, prob = model.predict_next_word(current_context)\n",
    "        \n",
    "        generated_words.append(next_word)\n",
    "        \n",
    "        if next_word in stop_tokens:\n",
    "            break\n",
    "        \n",
    "        if model.n == 1:\n",
    "            pass  \n",
    "        else:\n",
    "            current_context = current_context[1:] + [next_word]\n",
    "            if len(current_context) > model.n - 1:\n",
    "                current_context = current_context[-(model.n-1):]\n",
    "    \n",
    "    if include_context:\n",
    "        full_sentence = initial_context + generated_words\n",
    "    else:\n",
    "        full_sentence = generated_words\n",
    "    \n",
    "    return full_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e68742",
   "metadata": {},
   "source": [
    "## Experimentación con mejores modelos\n",
    "\n",
    "A continuación se intentará generar oraciones con los mejores modelos unigramas, bigramas y trigramas. De esta manera se podrá observar si los modelos son capaces de generar oraciones coherentes. curiosamente aunque la perplejidad más baja la tiene el modelo unigrama, las oraciones generadas por el modelo trigramas son las que más sentido tienen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6a547093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the or NUM satellites 's do the lumping , j article\n"
     ]
    }
   ],
   "source": [
    "sentence_unigram = generate_sentence(\n",
    "    model=model_20n_uni,\n",
    "    initial_context=['the'],\n",
    "    stop_tokens=['</s>'],\n",
    "    max_length=10,\n",
    "    include_context=True\n",
    ")\n",
    "print(' '.join(sentence_unigram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b6f90a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we . platforms those rick , -- the </s>\n"
     ]
    }
   ],
   "source": [
    "sentence_unigram = generate_sentence(\n",
    "    model=model_20n_uni,\n",
    "    initial_context=['we'],\n",
    "    stop_tokens=['</s>'],\n",
    "    max_length=10,\n",
    "    include_context=True\n",
    ")\n",
    "print(' '.join(sentence_unigram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c0c1e229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the same time . </s>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentence_bigram = generate_sentence(\n",
    "    model=model_bac_bi,\n",
    "    initial_context=['the'],\n",
    "    stop_tokens=['</s>'],\n",
    "    max_length=10,\n",
    "    include_context=True\n",
    ")\n",
    "print(' '.join(sentence_bigram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9241f2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we were n't know what i 'm not to the same\n"
     ]
    }
   ],
   "source": [
    "sentence_bigram = generate_sentence(\n",
    "    model=model_bac_bi,\n",
    "    initial_context=['we'],\n",
    "    stop_tokens=['</s>'],\n",
    "    max_length=10,\n",
    "    include_context=True\n",
    ")\n",
    "print(' '.join(sentence_bigram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f6a3d59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do n't know what i 'm not to the same time . </s>\n"
     ]
    }
   ],
   "source": [
    "sentence_bigram = generate_sentence(\n",
    "    model=model_bac_bi,\n",
    "    initial_context=['do'],\n",
    "    stop_tokens=['</s>'],\n",
    "    max_length=15,\n",
    "    include_context=True\n",
    ")\n",
    "print(' '.join(sentence_bigram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "89d90224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how do you think you 're not going to be a good thing . </s>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentence = generate_sentence(\n",
    "    model=model_bac_tri,\n",
    "    initial_context=['how','do'],\n",
    "    stop_tokens=['</s>'],\n",
    "    max_length=15,\n",
    "    include_context=True\n",
    ")\n",
    "print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "88402edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> this is the best of all the time . </s>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentence = generate_sentence(\n",
    "    model=model_bac_tri,\n",
    "    initial_context=['<s>','this'],\n",
    "    stop_tokens=['</s>'],\n",
    "    max_length=15,\n",
    "    include_context=True\n",
    ")\n",
    "print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "02ef643b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the problem is that i have to go to the point of view . </s>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentence = generate_sentence(\n",
    "    model=model_bac_tri,\n",
    "    initial_context=['the','problem'],\n",
    "    stop_tokens=['</s>'],\n",
    "    max_length=15,\n",
    "    include_context=True\n",
    ")\n",
    "print(' '.join(sentence))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
